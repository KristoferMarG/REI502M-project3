---
title: "Project 3 - Cluster Analysis"
author: 
  - Jón Þorsteinsson - jth56@hi.is
  - Kristófer Már Gíslason - kmg14@hi.is
output: 
  html_document:
    css: styles.css
    theme: lumen
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(cluster)
library(merTools)
```

### 1. Objectives

Our main obective was to determine with the highest possible accuracy what type of glass is found. Our ideal results would include 7 well defined clusters where each cluster would represent a glass type. The reason this can be found usefull is because of criminological investigations. Where at a scene of a crime glass can be correctly identified and possibly be used as valuable evidence.




### 2. Data set description

Without any preprocessing our data set has 214 different instances that each contain 10 different attributes and one class attribute that tells us what kind of glass it is from the 7 possible options.

| Nr. | Name | Type | Description |
| --- | ---- | ---- | ----------- |
| 1. | Id| numerical | number: 1 to 214 |
| 2. | RI| numerical | Refractive Index |
| 3. | Na| numerical | Sodium |
| 4. | Mg| numerical | Magnesium |
| 5. | Al| numerical | Aluminum |
| 6. | Si| numerical | Silicon |
| 7. | K | numerical | Potassium |
| 8. | Ca| numerical | Calcium|
| 9. | Ba |numerical | Barium |
| 10. |Fe |numerical | Iron| 
| 11. | Class | nominal | class - (building_windows_float_processed,building_windows_non_float_processed,vehicle_windows_float_processed, vehicle_windows_non_float_processed,containers,tableware,headlamps)|

#Preprocessing

We began by looking at all our attributes and noticed that the first one **Id** is completely useless to us because it only numbers the instances which we don't need. We also noticed that the class attributes never results to the glass being *vehicle_windows_non_float_processed* for this dataset so we should get one fewer clusters in the final result. All other attributes seem like they might have some interesting information so we include them. 



```{r data, tidy = TRUE}


# read in data file
glass <- read.csv("glass.csv")

# remove the Id attribute
glass <- glass[2:11]




```

### 3. K-means and Hieracrhical clustering


```{r test}

# Prepare Data
glass <- na.omit(glass) # listwise deletion of missing
glass <- scale(glass) # standardize variables


# random subsample from dataset
#randsample <- glass[sample(1:nrow(glass), 20 , replace=FALSE),]

# running k-means with k = 3
k.means.fit <- kmeans(glass, 6)

# plotting the clusters
clusplot(glass, k.means.fit$cluster,
         main='2D representation of the Cluster solution',
         color=TRUE, shade=TRUE, labels=2, lines=0)



# Determine number of clusters
#wss <- (nrow(glass)-2)*sum(apply(glass,2,var))
#for (i in 2:15) wss[i] <- sum(kmeans(glass, 
#  	centers=i)$withinss)
#plot(1:15, wss, type="b", xlab="Number of Clusters",
#  ylab="Within groups sum of squares")


# K-Means Cluster Analysis k=5
#fit <- kmeans(glass, 7) 
# get cluster means 
#aggregate(glass,by=list(fit$cluster),FUN=mean)
# append cluster assignment
#glass <- data.frame(glass, fit$cluster)

# Ward Hierarchical Clustering
#d <- dist(glass, method = "euclidean") # distance matrix
#fit <- hclust(d, method="ward.D") 
#plot(fit) # display dendogram
#groups <- cutree(fit, k=7) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters 
#rect.hclust(fit, k=7, border="blue")

```



```{r results="hide",warning=FALSE}

```



### 4. Comparisons of K-means and Hierarchical










